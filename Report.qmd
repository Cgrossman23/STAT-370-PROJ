---
title: "title"
format: pdf
author: Ashley Ciss, Coleton Grossman, William Quinn
editor: visual
indent: true
whitespace: small
---

# I. Introduction

Along the St. Mary’s River in Michigan, there are shores being affected by the wake of ships passing through. These wakes can be between one and three meters large and eventually stir up the areas of the river and cause plant disruption. In order to understand the effect of these waves, the density of the plants, bulrush and cattail need to be found. In this specific study, there were four different collection sites, each with a control side and an exposed side.  Each data collection included certain characteristics of the data sight collection. Some of the important ones include exposure, water depth, slope, fetch, and cost distance. The main goal of the data analysis was to create a predictive model that would output the density or presence/absence of these plants in this river.

Due to the nature and situation of the sites, there was geographical and spatial correlation. Not only was each sight correlated with one another, there were transects vertical and horizontal that also contributed to the correlation. The spatial and geographical set ups of these sites play a significant role in understanding and creating a predictive model. Understanding what the river looks like as well the sites seemed to be one of the most important parts of the process. The data also did not follow a normal distribution, so there were multiple tests completed to find the best fitting distribution for the data, which was a negative binomial distribution. Using both the correlation restrictions and the client’s needs, multiple models were created and tested against each other in order to find the best one. There are different types of models that can be created to accurately represent the data, such as mixed effects, zero inflated models, and logistic regression. The best model for the data that accurately predict the outcome of presence or absence was the logistic regression. Once the best model was found, there was a Bayesian analysis completed because the spatial correlation aspect does not need to be included in the model.

# II. Methods

The consulting process was divided into two major phases: an exploratory data analysis phase and explanatory modeling phase. Most of the statistical analysis and modeling was conducted via R-Studio while some handling of geo-spatial data was conducted via GIS.

### II.a. Data Visualization

The exploratory data analysis phase primarily constituted data visualizations such as bar graphs, scatter plots, and spatial data visualization maps. Key packages utilized in this phase were ggplot2, ggmap, and the sf package.

### II.b. Explanatory Modeling

The modeling phase of this project consisted of four distinct sub-phases: creating geographical correlation matrices, creating and testing zero-inflated models (ZIM’s), creating and testing mixed effect models (with and without ZIM elements), and the creation of two global models (a ZIM and a logistic regression model) with spatial lag explanatory variables. All models are explanatory models and seek to isolate and identify the influence of the variable *exposure* while controlling for the influence of potentially other significant variables such as *water_depth* and *speed_limit*.

#### II.b.1. **Geographical Correlation Matrices**

This code section was conducted with the purpose of fully capturing the maximum number of geographical correlations as defined under the Moran’s I equation. The Moran’s I equation resembles the standard variance equation; except that it seeks to account for the strength (or weakness) of geographical correlation via a weighted matrix. The formula for Moran’s I is as follows:

$$
I = \frac{N \sum_{i=1}^{n}\sum_{j=1}^{n}W_{ij}(X_i - \bar{X})(X_j - \bar{X})}{(\sum_{i=1}^{n}\sum_{j=1}^{n}W_{ij}) \sum_{i=1}^{n}(X_i - \bar{X})^2}
$$

Moran’s I is a measurement that ranges from \[-1,1\]. A value of 1 represents perfect positive autocorrelation. This would be a geographical data set in which values are perfectly geographically close (or attracted) to other similarly valued observations. A value of -1 represents perfect negative autocorrelation and means that data values are perfectly geographical distant (or repulsed) by other similarly valued observations. Moran’s I values that are near 0 indicate a lack of geographical correlation.

It was found necessary to calculate this measure due to the perceived violation of geographical independence by our data set. Our preliminary data visualizations displayed that plots with plant presence tended to clump together in chunks, indicating the presence of positive autocorrelation. By calculating the Moran’s I measurement we were able to verify the validity or invalidity of non-geographic models so as to confirm the presence of geographical correlations. Furthermore, the spatial weights matrix produced was used to create the spatial lag elements in our final global model.

A separate spatial weights matrix was constructed for each of our 4 non-exposed plots due to the differing plant densities observed across them. No spatial weights matrix was constructed for the 4 exposed plots due to the lack of any plant present plots in these segments.  These spatial weights matrices account for are weighted in the sense that instead of accounting for presence/absence of roots, they account for the root density when identifying the strength between two neighboring observations. The pseudo-code for the creation of each of these 4 individual weights matrices and Moran’s I measurements is below. Via this function we produced Moran’s I measurements that ranged from roughly \[0.292, 0.81\]. This indicates a moderate to strong geographical influence on plant root density.

Pseudo-code:

// Step 1: Extract spatial coordinates

Set coordinates_matrix to the combination of latitude and longitude columns from the dataset

// Step 2: Define a sequence of distance thresholds to test

Set distance_values to a sequence from the minimum to maximum distance (e.g., 0.000001 to 0.001 with small increments)

// Step 3: Initialize a container for Moran’s I values at each distance

Create moran_I_values as a list of NA values, same length as distance_values

// Step 4: Initialize variables to track the maximum Moran’s I and its associated distance

Set max_moran_I to negative infinity

Set optimal_distance to NA

Set optimal_neighbors to NULL

Set optimal_weights to NULL

// Step 5: For each candidate distance threshold, do:

For each distance in distance_values:

    - Identify neighbor relationships among coordinates using a fixed maximum distance

      neighbors ← all pairs of points within this distance

    - If no neighbors are found, skip to the next distance

    - Compute the distances between all neighbors

    - Construct spatial weights: inverse of distance, row-standardized

    - Calculate Moran’s I statistic for the outcome variable (e.g., population density) using the weights

    - Store the Moran’s I value

    - If this Moran’s I is the highest so far:

        • Update max_moran_I

        • Save the current distance as optimal_distance

        • Save the neighbor structure and weights

End pseudo code.

#### II.b.2. ZIM

The first explanatory models were constructed with just a zero-inflated element. These models were created in order to test for the significance of geographical correlations within each plot against a properly fitted model. So as to account for clustering effects 4 separate models were constructed: one for each unexposed plot per site. Once a properly fitted model was constructed for each plot, the residuals of the model were tested against the spatial weighted matrix of the plot. This was conducted via the moran.test command found in the *spdep* package.

The assumed underlying distribution for the zero-inflated model was a Poisson distribution. The formula for this model is as follows:

$$
P(y_i = 0) = \phi_i + (1 - \phi_i) * e^{-\lambda_i}
$$

$$
P(y_i = k) = (1 - \phi_i)\frac{e^{-\lambda_i} * \lambda_i^k}{k!}
$$

$$
\text{Where } \lambda_i = e^{x_i\beta} 
$$

#### II.b.3. Mixed-Effect Models

Due to the cluster aspect of the data and four different collection sites, a mixed effect model was assumed to be an accurate representation of the data. The clustered nature of the locations causes a lack of independent, which indicates that a random effect would help represent these clusters. Using the lme4 package in R, a mixed effect model can be used. The first model ran was just a baseline model with the individual sites being a random effect and the only explanatory variable, using the full data set. Using this model, the calculated r-squared was found to be 15.85%, so about 15.85% of the variance was due to the clustered nature of the sites. Within each of these sites, exposure was nested, therefore adding exposure to the model as a fixed effect. This model now had a lower r-squared of 11.46%. Comparing the baseline model with model with exposure, using a log-likelihood test, the model with exposure included was better. This was also consistent with the AIC and BIC values found. Another model was run including water depth as another explanatory variable. The r-squared was found to be about 12.85%, and running the same likelihood tests, the full model was better. The last model ran was the full model plus an interaction term which was slightly better, there was not much of a difference.

These models are seemingly strong and explanatory, however, there is still some issues with correlation, as well as large numbers of zero response variables.

#### **II.b.4. Global Spatial-Lag Models**

Lastly, the creation of a global model was conducted in order to create a summary measure of the influence of the exposure variable across sites. This involved the creation of two models: a zero-inflated model which accounts for root density, and a logistic regression model that simply accounts for plant presence or absence.

#### **II.b.4.1. Global ZIM**

This model combines elements of a zero-inflated model, random intercepts, and geographical autocorrelation, where spatial lags are entered as predictor variables for each individual observation.  The underlying distribution is as follows:

Furthermore, the Poisson mean is calculated using the coefficient estimates for our explanatory variables and our spatial lag variables.

Lastly, our random intercept effects follow a normal distribution centered at a mean of 0 and a standard deviation derived from variance observed across *site_individual*.

#### **II.b.4.2. Global Logistic Regression**

The global logistic regression model constructed instead removes the zero-inflated aspect of the prior model. This model loses the nuance of root density counts in favor of simplicity and ease of interpretation. The underlying distribution is assumed to be a Bernoulli process with the following formation:

Again here our random intercepts follow a normal distribution centered at 0 and a standard deviation that is derived from variances across *site_individual*.

# III. Results

### III.a. Final Mixed-Effects Model

It was clear from the exploratory data analysis as well as the calculation of Moran’s I values that there was geographical correlation amongst the sites. The first step to try and remediate and account for the correlation was a mixed effect model. There were four different mixed effects model created each with a random intercept and different levels of predictor variables. As mentioned in section II.b.3, the best model with a random intercept was the full model, where the interaction term had a negligible significance. The differences in AIC can be seen in Table 1. When incorporating the zero-inflated model aspect with the same predictors, the AIC was drastically decreased, indicating that the zero inflated aspect was significant. Even though these analyses deemed appropriate due to the clustering of the four individual sites, there is still correlation horizontally and vertically that needs to be accounted for in the model.

### III.b. Final Zero Inflated Models

Due to the large number of zeros that were included in the data, a zero inflated model appeared to be a method that would yield significant results. As described in section II.b.4.1, the zero inflated model was predicting density by exposure, the spatial lags variable, and the random effect of individual sites. This model considers all the datapoints across each of the four sites. As seen in Table 2, there is a large AIC value as well as a high odds ratio. By itself these values do not mean much, however compared to other final models, conclusions can be made about the model. Another zero inflated model was created that had a site-specific spatial lag predictive variable along with exposure, cost, and individual site as a random effect. This method yielded a smaller AIC and odds ratio, as seem in Table 2. Comparatively, it appears that the site-specific model may be a better model than the global model.

### III.c. Final Logistic Regression Model

The last model created in hopes to accurately capture the data was site specific logistic regression with the same predictor variables including the random intercept effect. This model had a binary response variable, the presence of either of the plants would be a one, where absence would be a zero. This yielded an even lower AIC value as seen in Table 2. The AIC was improved greatly, indicating that the logistic regression may be the best fit for the data.

### **III.d. Model Comparison**

The zero inflated model and the logistic regression have different characteristics that could be more useful for the data and accurately predict presence or absence. The two zero inflated models are very complicated and may be hard to interpret the results and predictive outputs of the model. However, both models maintain the root density details. The observed and predicted values of the site specific zero inflated can be seen graphed in Graph 1.  It appears that the model accurately predicts the values, especially at zero, but there could have been a better fit with larger values. Logistic regression provides a slightly simpler and interpretable model. It does loose some of the detail in the root density that the zero inflated model preserves. In Graph 2, it appears that the model accurately can predict the presence or absence binary response. Based on the observed values of AIC and odds ratios, the logistic regression with site specific spatial lag predictor variables is the best fit for the data.

# IV. Conclusion

The main goal of the project and the client was to find a suitable, accurate, and interpretable model for the St. Mary’s River. With understanding the distributions, creating spatial lags to account for correlation, and the inclusions of mixed effects, the best model was the site-specific logistic regression. The binary response variable was deemed to be the most appropriate, due to the large number of zeros.

Although a valid logistic regression was an output of continued data analysis, there could have been a more thorough analysis completed with the Bayesian analysis as well as understanding the site-specific correlation. In the future, given more time and more data, a less complex correlation structure may yield better results. The zero inflated data and small number of observations did not help the analysis process and given more data these issues could be remediated.

\newpage

# Appendix

| Model | AIC Value |
|------------------------------------|------------------------------------|
| Baseline with individual site random intercept | 2378.9 |
| Exposure with individual site random intercept | 2370.4 |
| Water depth, exposure, and individual site random intercept | 2366.8 |
| Water depth, exposure, interaction term, and individual site random intercept | 2364.8 |
| Water depth, exposure, and individual site random intercept, zero inflated | 712.5 |

: Mixed Effect Models AIC Values

| Model                             | AIC   | P-Value | Exposure Odds Ration |
|-----------------------------------|-------|---------|----------------------|
| Global Zero Inflated              | 716   | 0.00044 | 353.01               |
| Site-Specific Zero Inflated       | 709.3 | 0.0178  | 144.43               |
| Site-Specific Logistic Regression | 159.7 | \*      | 101.94               |

: Final Model Testing Values

## Code

#### I. Libraries

```{r, warning=FALSE, message=FALSE}
library(RCurl)
library(janitor)
library(dplyr)
library(car)
library(flexplot)
library(MASS)
library(ggplot2)

#mixed model libraries
library(lme4)
library(HLMdiag)
library(flexplot)
library(MuMIn)
library(glmmTMB) 

#geographic regression libraries
library(spdep)
library(deldir)

#for zero inflated
library(pscl)
```

#### II. Data Manipulation and Cleaning

```{r, results='hide'}
data_link <- getURL("https://raw.githubusercontent.com/Cgrossman23/STAT-370-PROJ/refs/heads/main/cleaned_data.csv") 
wave <- read.csv(text = data_link)
wave <- as.data.frame(wave)


# make all var undercase

wave <- clean_names(wave)

# renaming response variables to better names

colnames(wave)[7] <- "presence_absence_sch"
colnames(wave)[8] <- "density_sch"
colnames(wave)[9] <- "presence_absence_typ"
colnames(wave)[10] <- "density_typ"
names(wave)

names(wave)

wave[, c(1,2,7:15)] <- lapply(wave[, c(1,2,7:15)], function(x) gsub("[^0-9.]", "", x))
wave[, c(1,2,7:15)] <- lapply(wave[, c(1,2,7:15)], as.numeric)

str(wave)

unique(wave$transect) 
unique(wave$site_combined) 
unique(wave$site_individual)
unique(wave$exposure)

rows_with_na <- wave[!complete.cases(wave), ] 
print(rows_with_na)  
unique(rows_with_na$site_combined)
wave <- na.omit(wave)

# Summarazing response variables
wave$presence_absence <- (wave$presence_absence_sch + wave$presence_absence_typ)
wave$density <- (wave$density_sch + wave$density_typ)

wave <- wave %>% mutate(plant_type = case_when( 
                presence_absence_typ ==  1 ~ "typ", 
                presence_absence_sch == 1 ~ "sch", 
                TRUE ~ NA_character_ ))


# Filter for Unexposed and Site

wave$longitude <- ifelse(wave$longitude > 0, -wave$longitude, wave$longitude)

wave2 <- wave %>% filter(exposure == "Unexposed")
wave3 <- wave %>% filter(exposure == "Exposed")

wave_a <- wave2 %>% filter(site_combined == "A")
wave_b <- wave2 %>% filter(site_combined == "B")
wave_c <- wave2 %>% filter(site_combined == "C")
wave_d <- wave2 %>% filter(site_combined == "D")

wave_a2 <- wave3 %>% filter(site_combined == "A")
wave_b2 <- wave3 %>% filter(site_combined == "B")
wave_c2 <- wave3 %>% filter(site_combined == "C")
wave_d2 <- wave3 %>% filter(site_combined == "D")

wave4 <- rbind(wave_a, wave_b, wave_c, wave_d, wave_a2, wave_b2, wave_c2, wave_d2)
```

#### III. Geographical Correlation

##### III.a. Site A

```{r}
# Site A
coords_a <- cbind(wave_a$latitude, wave_a$longitude)

distances <- seq(0.000001, 0.001, by = 0.000001)
values <- numeric(length(distances))
values[] <- NA  
mmi_a <- -Inf  
od_a <- NA
neighbors_a <- NULL
weights_a <- NULL
options(warn = -1)
for (i in seq_along(distances)) {
  neighbors <- dnearneigh(coords_a, d1 = 0, d2 = distances[i]) #insert cords
  if (sum(card(neighbors)) == 0) { next }
  dists <- nbdists(neighbors, coords_a) # and here
  weights <- nb2listw(neighbors, 
                        glist = lapply(dists, function(x) 1 / x), 
                        style = "W", 
                        zero.policy = TRUE)
  moran_results <- moran(wave_a$density, weights, length(neighbors), Szero(weights)) #insert density here
  values[i] <- moran_results$I
  
  if (!is.na(values[i]) && values[i] > mmi_a) {
    mmi_a <- values[i]
    od_a <- distances[i]
    neighbors_a <- neighbors
    weights_a <- weights
  }
}
cat("Maximum Moran's I:", mmi_a, "\n")
cat("Optimal Distance:", od_a, "\n")

plot(neighbors_a,coords_a, col = "red")
```

##### III.b. Site B

```{r}
coords_b <- cbind(wave_b$latitude, wave_b$longitude)
  
distances <- seq(0.00012, 0.001, by = 0.000001)
values <- numeric(length(distances))
values[] <- NA  
mmi_b <- -Inf  
od_b <- NA
neighbors_b <- NULL
weights_b <- NULL
options(warn = -1)
for (i in seq_along(distances)) {
  neighbors <- dnearneigh(coords_b, d1 = 0, d2 = distances[i]) #insert cords
  if (sum(card(neighbors)) == 0) { next }
  dists <- nbdists(neighbors, coords_b) # and here
  weights <- nb2listw(neighbors, 
                        glist = lapply(dists, function(x) 1 / x), 
                        style = "W", 
                        zero.policy = TRUE)
  moran_results <- moran(wave_b$density, weights, length(neighbors), Szero(weights)) #insert density here
  values[i] <- moran_results$I
  
  if (!is.na(values[i]) && values[i] > mmi_b) {
    mmi_b <- values[i]
    od_b <- distances[i]
    neighbors_b <- neighbors
    weights_b <- weights
  }
}
cat("Maximum Moran's I:", mmi_b, "\n")
cat("Optimal Distance:", od_b, "\n")

plot(neighbors_b,coords_b, col = "red")
```

##### III.c. Site C

```{r}
coords_c <- cbind(wave_c$latitude, wave_c$longitude)
  
distances <- seq(0.000001, 0.001, by = 0.000001)
values <- numeric(length(distances))
values[] <- NA  
mmi_c <- -Inf  
od_c <- NA
neighbors_c <- NULL
weights_c <- NULL
options(warn = -1)
for (i in seq_along(distances)) {
  neighbors <- dnearneigh(coords_c, d1 = 0, d2 = distances[i]) #insert cords
  if (sum(card(neighbors)) == 0) { next }
  dists <- nbdists(neighbors, coords_c) # and here
  weights <- nb2listw(neighbors, 
                        glist = lapply(dists, function(x) 1 / x), 
                        style = "W", 
                        zero.policy = TRUE)
  moran_results <- moran(wave_c$density, weights, length(neighbors), Szero(weights)) #insert density here
  values[i] <- moran_results$I
  
  if (!is.na(values[i]) && values[i] > mmi_c) {
    mmi_c <- values[i]
    od_c <- distances[i]
    neighbors_c <- neighbors
    weights_c <- weights
  }
}
cat("Maximum Moran's I:", mmi_c, "\n")
cat("Optimal Distance:", od_c, "\n")

plot(neighbors_c,coords_c, col = "red")
```

##### III.d. Site D

```{r}
coords_d <- cbind(wave_d$latitude, wave_d$longitude)

distances <- seq(0.00012, 0.001, by = 0.000001)
values <- numeric(length(distances))
values[] <- NA  
mmi_d <- -Inf  
od_d <- NA
neighbors_d <- NULL
weights_d <- NULL
options(warn = -1)
for (i in seq_along(distances)) {
  neighbors <- dnearneigh(coords_d, d1 = 0, d2 = distances[i]) #insert cords
  if (sum(card(neighbors)) == 0) { next }
  dists <- nbdists(neighbors, coords_d) # and here
  weights <- nb2listw(neighbors, 
                        glist = lapply(dists, function(x) 1 / x), 
                        style = "W", 
                        zero.policy = TRUE)
  moran_results <- moran(wave_d$density, weights, length(neighbors), Szero(weights)) #insert density here
  values[i] <- moran_results$I
  
  if (!is.na(values[i]) && values[i] > mmi_d) {
    mmi_d <- values[i]
    od_d <- distances[i]
    neighbors_d <- neighbors
    weights_d <- weights
  }
}
cat("Maximum Moran's I:", mmi_d, "\n")
cat("Optimal Distance:", od_d, "\n")

plot(neighbors_d,coords_d, col = "red")
```

#### IV. Zero Inflated Models

##### IV.a. Site A

```{r}
model_zero_a <- zeroinfl(density ~ water_depth , data = wave_a, dist="negbin")

summary(model_zero_a)

negbin_model_b <- glm.nb(density ~ water_depth, data = wave_a)
vuong(model_zero_a, negbin_model_b)

poisson_model_b <- glm(density ~ water_depth, family = poisson, data = wave_a)
vuong(model_zero_a, poisson_model_b)

AIC(model_zero_a, negbin_model_b)
BIC(model_zero_a, negbin_model_b)

observed_a <- table(wave_a$density)
predicted_a <- table(round(predict(model_zero_a, type = "response")))

barplot(rbind(observed_a, predicted_a), beside = TRUE, col = c("black", "red"), legend.text = c("Observed", "Predicted"))

model_zero_a$model_zero_a$df.residual

###

resid_a <- residuals(model_zero_a)

moran_resid_test <- moran.test(resid_a, weights_a)

print(moran_resid_test) # insignificant
```

##### IV.b. Site B

```{r}
model_zero_b <- zeroinfl(density ~ water_depth , data = wave_b, dist="negbin")
model_zero_b2 <- zeroinfl(density ~ water_depth , data = wave_b, dist="poisson")

summary(model_zero_b)
summary(model_zero_b2)

negbin_model_b <- glm.nb(density ~ water_depth, data = wave_b)
vuong(model_zero_b, negbin_model_b)

poisson_model_b <- glm(density ~ water_depth, family = poisson, data = wave_b)
vuong(model_zero_b2, poisson_model_b)

AIC(model_zero_b, poisson_model_b)
BIC(model_zero_b, poisson_model_b)

observed_b <- table(wave_b$density)
predicted_b <- table(round(predict(model_zero_b, type = "response")))

barplot(rbind(observed_b, predicted_b), beside = TRUE, col = c("black", "red"), legend.text = c("Observed", "Predicted"))

###

resid_b <- residuals(model_zero_b)

moran_resid_test <- moran.test(resid_b, weights_b)

print(moran_resid_test) # insignificant
```

##### IV.c. Site C

```{r}
model_zero_c <- zeroinfl(density ~ water_depth , data = wave_c, dist="negbin")
model_zero_c2 <- zeroinfl(density ~ water_depth , data = wave_c, dist="poisson")

summary(model_zero_c)
summary(model_zero_c2)

negbin_model_c <- glm.nb(density ~ water_depth, data = wave_c)
vuong(model_zero_c, negbin_model_c)

poisson_model_c <- glm(density ~ water_depth, family = poisson, data = wave_c)
vuong(model_zero_c2, poisson_model_c)


AIC(model_zero_c, negbin_model_c)
BIC(model_zero_c, negbin_model_c)

BIC(model_zero_c2, poisson_model_c)
AIC(model_zero_c2, poisson_model_c)


observed_c <- table(wave_c$density)
predicted_c <- table(round(predict(model_zero_c, type = "response")))

barplot(rbind(observed_c, predicted_c), beside = TRUE, col = c("black", "red"),
        legend.text = c("Observed", "Predicted"))

###

resid_c <- residuals(model_zero_c)

moran_resid_test <- moran.test(resid_c, weights_c)

print(moran_resid_test) # significant
```

##### IV.d. Site D

```{r}
model_zero_d <- zeroinfl(density ~ water_depth , data = wave_d, dist="negbin")
model_zero_d2 <- zeroinfl(density ~ water_depth , data = wave_d, dist="poisson")

summary(model_zero_d)
summary(model_zero_d2)

negbin_model_d <- glm.nb(density ~ water_depth, data = wave_d)
vuong(model_zero_d, negbin_model_d)

poisson_model_d <- glm(density ~ water_depth, family = poisson, data = wave_d)
vuong(model_zero_d2, poisson_model_d)

AIC(model_zero_d, negbin_model_d)
BIC(model_zero_d, negbin_model_d)

AIC(model_zero_d2, poisson_model_d)
BIC(model_zero_d2, poisson_model_d)

observed_d <- table(wave_d$density)
predicted_d <- table(round(predict(model_zero_d, type = "response")))

barplot(rbind(observed_d, predicted_d), beside = TRUE, col = c("black", "red"), legend.text = c("Observed", "Predicted"))

###

resid_d <- residuals(model_zero_d)

moran_resid_test <- moran.test(resid_d, weights_d)

print(moran_resid_test) # significant
```

#### V. Mixed Effects Models

##### V.a. Baseline

```{r}
model1 <- lmer(density ~ 1 + (1 | site_individual), data = wave4)
summary(model1)
r_squared <- r.squaredGLMM(model1)
print(r_squared)
```

##### V.b. Exp - Exposure Nested in site_individual

```{r}
model2 <- lmer(density ~ exposure + (1 | site_individual), data = wave4)
r_squared2 <- r.squaredGLMM(model2)
print(r_squared2)
anova(model2, model1)
```

##### V.c. Exp - Full Explanatory Variables

```{r}
model3 <- lmer(density ~  water_depth + exposure + (1 | site_individual), data = wave4)
r_squared3 <- r.squaredGLMM(model3)
print(r_squared3)
anova(model3, model2)
```

##### V.d. Exp - Interaction term with Exposure nested in site_combined

```{r}
model4 <- lmer(density ~ exposure*water_depth + (1 | site_individual), data = wave4)
r_squared4 <- r.squaredGLMM(model4)
print(r_squared4)
anova(model4, model3)
```

##### V.e. ZIM with Mixed Effect

```{r}
# model01 <- glmmTMB(density ~ exposure + water_depth + (1 | site_individual),
#                    ziformula = ~ 1,
#                    family = "genpois",
#                    data = wave4)
# summary(model01)
# r.squaredGLMM(model01)
# AIC(model01)
```

#### VI. Final Models

##### VI.a. Global ZIM

```{r}
coords <- cbind(wave4$latitude, wave4$longitude)
distances <- seq(0.00012, 0.001, by = 0.000001)
values <- numeric(length(distances))
values[] <- NA  
mmi <- -Inf  
od <- NA
neighbors <- NULL
weights <- NULL
options(warn = -1)
for (i in seq_along(distances)) {
  neighbors <- dnearneigh(coords, d1 = 0, d2 = distances[i]) #insert cords
  if (sum(card(neighbors)) == 0) { next }
  dists <- nbdists(neighbors, coords) # and here
  weights <- nb2listw(neighbors, 
                        glist = lapply(dists, function(x) 1 / x), 
                        style = "W", 
                        zero.policy = TRUE)
  moran_results <- moran(wave4$density, weights, length(neighbors), Szero(weights)) #insert density here
  values[i] <- moran_results$I
  
  if (!is.na(values[i]) && values[i] > mmi) {
    mmi <- values[i]
    od <- distances[i]
    neighbors <- neighbors
    weights <- weights
  }
}
cat("Maximum Moran's I:", mmi, "\n")
cat("Optimal Distance:", od, "\n")

plot(neighbors,coords, col = "red")

# Compute Moran’s I
moran_test <- moran.test(wave4$density, listw = weights, zero.policy = TRUE)
print(moran_test)

# Global Moran's I is highly significant.
```

```{r}
wave4$spatial_lag1 <- NA
wave4$spatial_lag2 <- NA
wave4$spatial_lag3 <- NA

weights_list <- list(
  "A" = weights_a,
  "D" = weights_b,
  "F" = weights_c,
  "H" = weights_d
)

for (s in unique(wave4$site_individual)) {
  if (s %in% names(weights_list)) {
    site_subset <- wave4[wave4$site_individual == s, ]
    W <- weights_list[[s]]
    wave4$spatial_lag1[wave4$site_individual == s] <- lag.listw(W, site_subset$density)
    wave4$spatial_lag2[wave4$site_individual == s] <- lag.listw(W, wave4$spatial_lag1[wave4$site_individual == s])
    wave4$spatial_lag3[wave4$site_individual == s] <- lag.listw(W, wave4$spatial_lag2[wave4$site_individual == s])
  } else {
    wave4$spatial_lag1[wave4$site_individual == s] <- 0
    wave4$spatial_lag2[wave4$site_individual == s] <- 0
    wave4$spatial_lag3[wave4$site_individual == s] <- 0
  }
}
```

```{r}

wave4$spatial_lag1_g <- lag.listw(weights, wave4$density)
wave4$spatial_lag2_g <- lag.listw(weights, wave4$spatial_lag1_g)
wave4$spatial_lag3_g <- lag.listw(weights, wave4$spatial_lag2_g) 

# spatial_G_NB <- glmmTMB(density ~ exposure + spatial_lag1_g + (1 | site_individual),
#   ziformula = ~ 1,
#   family = nbinom1,
#   data = wave4
# )
# 
# summary(spatial_G_NB)
# spatial_G_GP <- glmmTMB(density ~ exposure + spatial_lag1_g + (1 | site_individual),
#   ziformula = ~ 1,
#   family = genpois,
#   data = wave4
# )

# summary(spatial_G_GP)
# wave4$residuals <- residuals(spatial_G_NB)
# for (s in c("A", "D", "F", "H")) {
#   site_subset <- wave4[wave4$site_individual == s, ]
#   moran_test <- moran.test(site_subset$residuals, weights_list[[s]])
#   print(paste("Moran's I for site", s, ":", moran_test$estimate["Moran I statistic"]))
# }
```

##### VI.b. Site Specific Correlated - ZIM

```{r}
# spatial <- glmmTMB(density ~ exposure + water_depth + spatial_lag1 + (1 | site_individual),
#   ziformula = ~ 1,
#   family = nbinom1,
#   data = wave4
# )
# 
# # exposure, water_depth, slope_use, cost_small, fetch_projected, speed_limit
# spatial2 <- glmmTMB(density ~ exposure + cost_small + spatial_lag1 + spatial_lag2 + spatial_lag3 + (1 | site_individual),
#   ziformula = ~ 1,
#   family = genpois,
#   data = wave4
# )
# 
# summary(spatial)
# summary(spatial2)
# 
# wave4$residuals <- residuals(spatial)
# 
# for (s in c("A", "D", "F", "H")) {
#   site_subset <- wave4[wave4$site_individual == s, ]
#   moran_test <- moran.test(site_subset$residuals, weights_list[[s]])
#   print(paste("Moran's I for site", s, ":", moran_test$estimate["Moran I statistic"]))
# }
# 
# r.squaredGLMM(spatial)
# wave4$predicted_count <- predict(spatial, type = "response")
# 
# ggplot(wave4, aes(x = predicted_count, y = density)) +
#   geom_jitter(width = 0.2, height = 0.2, alpha = 0.4) +
#   geom_smooth(method = "loess", color = "red") +
#   labs(x = "Predicted Count", y = "Observed Count",
#        title = "Observed vs. Predicted (ZINB1 Model)")
```

##### VI.c. Site Specific Correlated - Logistic Regression

```{r}
# wave4$presence_absence <- (wave4$presence_absence_sch + wave4$presence_absence_typ)
# 
# spatial3 <- glmmTMB(presence_absence ~ exposure + cost_small + spatial_lag1 + spatial_lag2 + spatial_lag3 + (1 | site_individual), 
#                     data = wave4, 
#                     family = binomial(link = "logit"))
# 
# summary(spatial3)
# 
# wave4$residuals <- residuals(spatial3)
# 
# for (s in c("A", "D", "F", "H")) {
#   site_subset <- wave4[wave4$site_individual == s, ]
#   moran_test <- moran.test(site_subset$residuals, weights_list[[s]])
#   print(paste("Moran's I for site", s, ":", moran_test$estimate["Moran I statistic"]))
# }

# wave4$predicted_prob <- predict(spatial3, type = "response")
# 
# ggplot(wave4, aes(x = predicted_prob, y = presence_absence)) +
#   geom_jitter(height = 0.05, width = 0, alpha = 0.3) +
#   geom_smooth(method = "loess", formula = y ~ x, se = FALSE, color = "blue") +
#   labs(x = "Predicted Probability", y = "Observed Presence (1) / Absence (0)",
#        title = "Observed vs. Predicted (Logistic GLMM)") +
#   theme_minimal()
```
